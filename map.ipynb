{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (0.15.1)\n",
      "Requirement already satisfied: pandas in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: branca>=0.6.0 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from folium) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: numpy in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from folium) (1.26.1)\n",
      "Requirement already satisfied: requests in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from folium) (2.31.0)\n",
      "Requirement already satisfied: xyzservices in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from folium) (2023.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jinja2>=2.9->folium) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->folium) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->folium) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->folium) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/carlamandiola/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->folium) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install folium pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Load your dataset (Replace 'your_file.csv' with the actual file path)\n",
    "df = pd.read_csv(\"geo_CBP_apprehensions.csv\")\n",
    "\n",
    "# Create a base map centered at a general location (Mexico)\n",
    "m = folium.Map(location=[23.6345, -102.5528], zoom_start=5)\n",
    "\n",
    "# Loop through DataFrame and add markers\n",
    "for index, row in df.iterrows():\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    city, state, country = row['city_birth'], row['state_birth'], row['country_birth']\n",
    "    \n",
    "    if pd.notna(lat) and pd.notna(lon):  # Ensure lat/lon are not NaN\n",
    "        popup_text = f\"{city}, {state}, {country}\"\n",
    "        folium.Marker(\n",
    "            location=[lat, lon],\n",
    "            popup=popup_text,\n",
    "            tooltip=popup_text\n",
    "        ).add_to(m)\n",
    "\n",
    "# Save and display the map\n",
    "m.save(\"map.html\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Data:\n",
      "                    city_birth country_birth      FY  Count\n",
      "0      \"SUBJECT ILLEGALLY ENTE      HONDURAS  2019.0      1\n",
      "1          #1 CANTON NATIVIDAD   EL SALVADOR  2019.0      1\n",
      "2                    (UNKNOWN)        MEXICO  2019.0      1\n",
      "3                            ,     GUATEMALA  2019.0      2\n",
      "4                            ,        MEXICO  2019.0      1\n",
      "...                        ...           ...     ...    ...\n",
      "72440                tlaquilpa        MEXICO  2019.0      1\n",
      "72441                  unknown     NICARAGUA  2022.0      1\n",
      "72442               villanueva     NICARAGUA  2019.0      1\n",
      "72443                   xalapa        MEXICO  2019.0      1\n",
      "72444    zihuatanejo de azueta        MEXICO  2019.0      1\n",
      "\n",
      "[72445 rows x 4 columns]\n",
      "Sorted and recalculated dataset saved to 'sorted_by_adjusted_growth.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"geo_CBP_apprehensions.csv\"  # Replace with the path to your uploaded file\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extract numeric fiscal year from the 'FY' column\n",
    "df['FY'] = df['FY'].str.extract(r'(\\d{4})').astype(float)\n",
    "\n",
    "# Filter data for FY 2019 and FY 2022\n",
    "df_filtered = df[df['FY'].isin([2019, 2022])]\n",
    "\n",
    "# Group by relevant columns and count rows (each row represents one person)\n",
    "df_grouped = df_filtered.groupby(['city_birth', 'country_birth', 'FY']).size().reset_index(name='Count')\n",
    "\n",
    "# Check the grouped data\n",
    "print(\"Grouped Data:\")\n",
    "print(df_grouped)\n",
    "\n",
    "# Pivot the data to have FYs as columns\n",
    "df_pivot = df_grouped.pivot(index=['city_birth', 'country_birth'], columns='FY', values='Count').fillna(0)\n",
    "\n",
    "# Ensure 2019 and 2022 columns exist\n",
    "if 2019 in df_pivot.columns and 2022 in df_pivot.columns:\n",
    "    # Rename columns for clarity\n",
    "    df_pivot.columns = ['2019', '2022']\n",
    "\n",
    "    # Calculate Growth\n",
    "    df_pivot['Growth'] = ((df_pivot['2022'] - df_pivot['2019']) / df_pivot['2019'].replace(0, None)) * 100\n",
    "\n",
    "    # Handle Adjusted Growth for 2019 = 0\n",
    "    df_pivot['Adjusted Growth'] = df_pivot['Growth']\n",
    "    df_pivot.loc[df_pivot['2019'] == 0, 'Adjusted Growth'] = df_pivot['2022']\n",
    "\n",
    "    # Replace NaN or infinite values with 0\n",
    "    df_pivot['Growth'] = df_pivot['Growth'].fillna(0)\n",
    "    df_pivot['Adjusted Growth'] = df_pivot['Adjusted Growth'].fillna(0)\n",
    "\n",
    "    # Sort by Adjusted Growth\n",
    "    df_sorted = df_pivot.sort_values(by='Adjusted Growth', ascending=False)\n",
    "\n",
    "    # Save the sorted DataFrame to a new CSV file\n",
    "    output_file = \"sorted_by_adjusted_growth.csv\"\n",
    "    df_sorted.to_csv(output_file)\n",
    "\n",
    "    print(f\"Sorted and recalculated dataset saved to '{output_file}'.\")\n",
    "else:\n",
    "    print(\"Error: FY 2019 or FY 2022 is missing in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeo_CBP_apprehensions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your uploaded file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Extract numeric fiscal year from the 'FY' column\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFY\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"geo_CBP_apprehensions.csv\"  # Replace with the path to your uploaded file\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extract numeric fiscal year from the 'FY' column\n",
    "df['FY'] = df['FY'].str.extract(r'(\\d{4})').astype(float)\n",
    "\n",
    "# Filter data for FY 2019 and FY 2022\n",
    "df_filtered = df[df['FY'].isin([2019, 2022])]\n",
    "\n",
    "# Group by relevant columns and count rows (each row represents one person)\n",
    "df_grouped = df_filtered.groupby(['city_birth', 'country_birth', 'FY']).size().reset_index(name='Count')\n",
    "\n",
    "# Pivot the data to have FYs as columns\n",
    "df_pivot = df_grouped.pivot(index=['city_birth', 'country_birth'], columns='FY', values='Count').fillna(0)\n",
    "\n",
    "# Ensure 2019 and 2022 columns exist\n",
    "if 2019 in df_pivot.columns and 2022 in df_pivot.columns:\n",
    "    # Rename columns for clarity\n",
    "    df_pivot.columns = ['2019', '2022']\n",
    "\n",
    "    # Calculate Growth\n",
    "    df_pivot['Growth'] = ((df_pivot['2022'] - df_pivot['2019']) / df_pivot['2019'].replace(0, None)) * 100\n",
    "\n",
    "    # Handle Adjusted Growth for 2019 = 0\n",
    "    df_pivot['Adjusted Growth'] = df_pivot['Growth']\n",
    "    df_pivot.loc[df_pivot['2019'] == 0, 'Adjusted Growth'] = df_pivot['2022']\n",
    "\n",
    "    # Replace NaN or infinite values with 0\n",
    "    df_pivot['Growth'] = df_pivot['Growth'].fillna(0)\n",
    "    df_pivot['Adjusted Growth'] = df_pivot['Adjusted Growth'].fillna(0)\n",
    "\n",
    "    # Round Growth and Adjusted Growth to 2 decimal places\n",
    "    df_pivot['Growth'] = df_pivot['Growth'].round(2)\n",
    "    df_pivot['Adjusted Growth'] = df_pivot['Adjusted Growth'].round(2)\n",
    "\n",
    "    # Sort by Adjusted Growth\n",
    "    df_sorted = df_pivot.sort_values(by='Adjusted Growth', ascending=False)\n",
    "\n",
    "    # Save the sorted DataFrame to a new CSV file\n",
    "    output_file = \"sorted_by_adjusted_growth.csv\"\n",
    "    df_sorted.to_csv(output_file)\n",
    "\n",
    "    print(f\"Sorted and recalculated dataset saved to '{output_file}'.\")\n",
    "else:\n",
    "    print(\"Error: FY 2019 or FY 2022 is missing in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map has been saved as 'belize.html'. Open it in your browser to explore.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "\n",
    "# Load dataset (Replace with actual file path)\n",
    "file_path = \"geo_CBP_apprehensions.csv\"\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extract numeric fiscal year (e.g., \"FY2010\" → 2010)\n",
    "df['FY'] = df['FY'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# Filter for Mexico\n",
    "df_mexico = df[df['country_birth'].str.upper() == \"BELIZE\"]\n",
    "\n",
    "# Group by city and year to count people per city per year\n",
    "df_grouped = df_mexico.groupby(['city_birth', 'state_birth', 'lat', 'lon', 'FY']).size().reset_index(name='count')\n",
    "\n",
    "# Create a base map centered on Mexico\n",
    "m = folium.Map(location=[23.6345, -102.5528], zoom_start=5)\n",
    "\n",
    "# Prepare data for TimestampedGeoJson\n",
    "features = []\n",
    "for _, row in df_grouped.iterrows():\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    city, state, year, count = row['city_birth'], row['state_birth'], row['FY'], row['count']\n",
    "    \n",
    "    if pd.notna(lat) and pd.notna(lon):  # Ensure lat/lon are valid\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [lon, lat],  # GeoJSON format: [longitude, latitude]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"time\": f\"{year}-01-01\",  # Use a consistent date format per year\n",
    "                \"popup\": f\"<b>City:</b> {city}<br><b>State:</b> {state}<br><b>Year:</b> {year}<br><b>People:</b> {count}\",\n",
    "                \"icon\": \"circle\",\n",
    "                \"iconstyle\": {\n",
    "                    \"color\": \"red\",\n",
    "                    \"fillColor\": \"red\",\n",
    "                    \"fillOpacity\": 0.6,\n",
    "                    \"radius\": (count ** 0.5) * 2  # Adjust size dynamically\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        features.append(feature)\n",
    "\n",
    "# Add Timestamped GeoJson (Animated without visible timeline bar)\n",
    "TimestampedGeoJson(\n",
    "    {\"type\": \"FeatureCollection\", \"features\": features},\n",
    "    period=\"P1Y\",  # One-year intervals\n",
    "    add_last_point=True,\n",
    "    auto_play=True,  # Automatically play animation\n",
    "    loop=True,  # Allow looping\n",
    "    max_speed=1,  # 1 FPS animation speed\n",
    "    loop_button=False,  # Hide loop button\n",
    "    date_options=\"YYYY\",\n",
    "    time_slider_drag_update=False,  # Hide the time slider\n",
    ").add_to(m)\n",
    "\n",
    "# Save and display map\n",
    "output_file = \"belize.html\"\n",
    "m.save(output_file)\n",
    "\n",
    "print(f\"Map has been saved as '{output_file}'. Open it in your browser to explore.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map has been saved as 'belize.html'. Open it in your browser to explore.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "\n",
    "# Load dataset (Replace with actual file path)\n",
    "file_path = \"geo_CBP_apprehensions.csv\"\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extract numeric fiscal year (e.g., \"FY2010\" → 2010)\n",
    "df['FY'] = df['FY'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# Filter for Mexico\n",
    "df_mexico = df[df['country_birth'].str.upper() == \"BELIZE\"]\n",
    "\n",
    "# Group by city and year to count people per city per year\n",
    "df_grouped = df_mexico.groupby(['city_birth', 'state_birth', 'lat', 'lon', 'FY']).size().reset_index(name='count')\n",
    "\n",
    "# Create a base map centered on Mexico\n",
    "m = folium.Map(location=[23.6345, -102.5528], zoom_start=5)\n",
    "\n",
    "# Prepare data for TimestampedGeoJson\n",
    "features = []\n",
    "for _, row in df_grouped.iterrows():\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    city, state, year, count = row['city_birth'], row['state_birth'], row['FY'], row['count']\n",
    "    \n",
    "    if pd.notna(lat) and pd.notna(lon):  # Ensure lat/lon are valid\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [lon, lat],  # GeoJSON format: [longitude, latitude]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"time\": f\"{year}-01-01\",  # Use a consistent date format per year\n",
    "                \"popup\": f\"<b>City:</b> {city}<br><b>State:</b> {state}<br><b>Year:</b> {year}<br><b>People:</b> {count}\",\n",
    "                \"icon\": \"circle\",\n",
    "                \"iconstyle\": {\n",
    "                    \"color\": \"red\",\n",
    "                    \"fillColor\": \"red\",\n",
    "                    \"fillOpacity\": 0.6,\n",
    "                    \"radius\": (count ** 0.5) * 2  # Adjust size dynamically\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        features.append(feature)\n",
    "\n",
    "# Add Timestamped GeoJson (for animated year slider)\n",
    "TimestampedGeoJson(\n",
    "    {\"type\": \"FeatureCollection\", \"features\": features},\n",
    "    period=\"P1Y\",  # One-year intervals\n",
    "    add_last_point=True,\n",
    "    auto_play=False,\n",
    "    loop=False,\n",
    "    max_speed=1,\n",
    "    loop_button=True,\n",
    "    date_options=\"YYYY\",\n",
    "    time_slider_drag_update=True,\n",
    ").add_to(m)\n",
    "\n",
    "# Save and display map\n",
    "output_file = \"belize.html\"\n",
    "m.save(output_file)\n",
    "\n",
    "print(f\"Map has been saved as '{output_file}'. Open it in your browser to explore.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map has been saved as 'belize.html'. Open it in your browser to explore.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "\n",
    "# Load dataset (Replace with actual file path)\n",
    "file_path = \"geo_CBP_apprehensions.csv\"\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extract numeric fiscal year (e.g., \"FY2010\" → 2010)\n",
    "df['FY'] = df['FY'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# Filter for Belize\n",
    "df_belize = df[df['country_birth'].str.upper() == \"BELIZE\"]\n",
    "\n",
    "# Group by city and year to count people per city per year\n",
    "df_grouped = df_belize.groupby(['city_birth', 'state_birth', 'lat', 'lon', 'FY']).size().reset_index(name='count')\n",
    "\n",
    "# Create a base map centered on Belize\n",
    "m = folium.Map(location=[17.1899, -88.4976], zoom_start=7)  # Belize's coordinates\n",
    "\n",
    "# Prepare data for TimestampedGeoJson\n",
    "features = []\n",
    "for _, row in df_grouped.iterrows():\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    city, state, year, count = row['city_birth'], row['state_birth'], row['FY'], row['count']\n",
    "    \n",
    "    if pd.notna(lat) and pd.notna(lon):  # Ensure lat/lon are valid\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [lon, lat],  # GeoJSON format: [longitude, latitude]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"time\": f\"{year}-01-01\",  # Use a consistent date format per year\n",
    "                \"popup\": f\"<b>City:</b> {city}<br><b>State:</b> {state}<br><b>Year:</b> {year}<br><b>People:</b> {count}\",\n",
    "                \"icon\": \"circle\",\n",
    "                \"iconstyle\": {\n",
    "                    \"color\": \"red\",\n",
    "                    \"fillColor\": \"red\",\n",
    "                    \"fillOpacity\": 0.6,\n",
    "                    \"radius\": (count ** 0.5) * 2  # Adjust size dynamically\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        features.append(feature)\n",
    "\n",
    "# Add Timestamped GeoJson (for animated year slider)\n",
    "TimestampedGeoJson(\n",
    "    {\"type\": \"FeatureCollection\", \"features\": features},\n",
    "    period=\"P1Y\",  # One-year intervals\n",
    "    add_last_point=True,\n",
    "    auto_play=False,\n",
    "    loop=False,\n",
    "    max_speed=1,\n",
    "    loop_button=True,\n",
    "    date_options=\"YYYY\",\n",
    "    time_slider_drag_update=True,\n",
    ").add_to(m)\n",
    "\n",
    "# Save and display map\n",
    "output_file = \"belize.html\"\n",
    "m.save(output_file)\n",
    "\n",
    "print(f\"Map has been saved as '{output_file}'. Open it in your browser to explore.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map has been saved as 'belize.html'. Open it in your browser to explore.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "\n",
    "# Load dataset (Replace with actual file path)\n",
    "file_path = \"geo_CBP_apprehensions.csv\"\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Extract numeric fiscal year (e.g., \"FY2010\" → 2010)\n",
    "df['FY'] = df['FY'].str.extract(r'(\\d{4})').astype(int)\n",
    "\n",
    "# Filter for Belize\n",
    "df_belize = df[df['country_birth'].str.upper() == \"BELIZE\"]\n",
    "\n",
    "# Group by city and year to count people per city per year\n",
    "df_grouped = df_belize.groupby(['city_birth', 'state_birth', 'lat', 'lon', 'FY']).size().reset_index(name='count')\n",
    "\n",
    "# Create a base map (zoom will be adjusted later)\n",
    "m = folium.Map(zoom_start=7)\n",
    "\n",
    "# Prepare data for TimestampedGeoJson\n",
    "features = []\n",
    "for _, row in df_grouped.iterrows():\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    city, state, year, count = row['city_birth'], row['state_birth'], row['FY'], row['count']\n",
    "    \n",
    "    if pd.notna(lat) and pd.notna(lon):  # Ensure lat/lon are valid\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [lon, lat],  # GeoJSON format: [longitude, latitude]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"time\": f\"{year}-01-01\",  # Use a consistent date format per year\n",
    "                \"popup\": f\"<b>City:</b> {city}<br><b>State:</b> {state}<br><b>Year:</b> {year}<br><b>People:</b> {count}\",\n",
    "                \"icon\": \"circle\",\n",
    "                \"iconstyle\": {\n",
    "                    \"color\": \"red\",\n",
    "                    \"fillColor\": \"red\",\n",
    "                    \"fillOpacity\": 0.6,\n",
    "                    \"radius\": (count ** 0.5) * 2  # Adjust size dynamically\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        features.append(feature)\n",
    "\n",
    "# Add Timestamped GeoJson (for animated year slider)\n",
    "TimestampedGeoJson(\n",
    "    {\"type\": \"FeatureCollection\", \"features\": features},\n",
    "    period=\"P1Y\",  # One-year intervals\n",
    "    add_last_point=True,\n",
    "    auto_play=False,\n",
    "    loop=False,\n",
    "    max_speed=1,\n",
    "    loop_button=True,\n",
    "    date_options=\"YYYY\",\n",
    "    time_slider_drag_update=True,\n",
    ").add_to(m)\n",
    "\n",
    "# Auto-zoom to fit all points in Belize\n",
    "bounds = [[row['lat'], row['lon']] for _, row in df_grouped.iterrows() if pd.notna(row['lat']) and pd.notna(row['lon'])]\n",
    "if bounds:\n",
    "    m.fit_bounds(bounds)\n",
    "\n",
    "# Save and display map\n",
    "output_file = \"belize.html\"\n",
    "m.save(output_file)\n",
    "\n",
    "print(f\"Map has been saved as '{output_file}'. Open it in your browser to explore.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
